{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPREqfitKVGdKUdgV+Shnmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babupallam/PyTorch-Learning-Repository/blob/main/04_Training_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will focus on training neural networks in PyTorch, covering topics like training loops, loss calculation, backpropagation, optimization, and monitoring model performance. Understanding how to structure a proper training loop and optimize your model’s weights is critical to developing an efficient and accurate neural network.\n"
      ],
      "metadata": {
        "id": "V5OseqopFx-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.1. Overview of the Training Process**\n",
        "- **Training a neural network** involves iteratively updating model parameters (weights and biases) using an optimization algorithm like Stochastic Gradient Descent (SGD) to minimize the loss function.\n",
        "- The steps to train a neural network are:\n",
        "  1. **Forward Pass**: Input data is passed through the network to compute predictions.\n",
        "  2. **Loss Calculation**: The loss function computes how far the predicted values are from the actual values.\n",
        "  3. **Backward Pass (Backpropagation)**: Gradients are computed for the model parameters using automatic differentiation.\n",
        "  4. **Optimization**: The optimizer updates the parameters based on the gradients to reduce the loss.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NuCywh_PpHyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.2. Key Components for Training**\n",
        "- **Model**: Defines the neural network structure using `torch.nn.Module`.\n",
        "- **Loss Function**: Measures the error between the predicted and true values. Common loss functions include:\n",
        "  - `nn.MSELoss()` for regression.\n",
        "  - `nn.CrossEntropyLoss()` for classification.\n",
        "- **Optimizer**: Updates the model's parameters based on the computed gradients.\n",
        "  - Common optimizers: `optim.SGD()`, `optim.Adam()`.\n",
        "- **Training Loop**: Iterates over the dataset for a specified number of epochs, performing forward and backward passes, and updating the model’s weights.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "42E2pL3y8NyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.3. Full Training Loop Implementation**\n",
        "\n",
        "Let’s walk through the steps of training a neural network in PyTorch, from model initialization to optimizing over multiple epochs.\n",
        "\n",
        "---\n",
        "\n",
        "**4.3.1. Example Neural Network Training on MNIST**\n",
        "\n",
        "In this example, we will build and train a simple feedforward neural network to classify images from the MNIST dataset. The network consists of fully connected layers with ReLU activations and is trained using the Cross-Entropy Loss for multi-class classification.\n",
        "\n",
        "**Demonstration: Full Training Loop on MNIST**"
      ],
      "metadata": {
        "id": "1No9b3ac8O0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define a simple neural network with two hidden layers\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # Input layer: 28x28=784, Hidden layers: 128 and 64 neurons, Output layer: 10 classes (digits 0-9)\n",
        "        self.fc1 = nn.Linear(28*28, 128)  # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(128, 64)     # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(64, 10)      # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the input image (28x28 pixels) into a vector of 784 elements\n",
        "        x = x.view(-1, 28*28)  # Flatten the input (28x28 images -> 784 inputs)\n",
        "\n",
        "        # Pass through the first fully connected layer and apply ReLU activation\n",
        "        x = torch.relu(self.fc1(x))  # Apply ReLU to first hidden layer\n",
        "\n",
        "        # Pass through the second fully connected layer and apply ReLU activation\n",
        "        x = torch.relu(self.fc2(x))  # Apply ReLU to second hidden layer\n",
        "\n",
        "        # Pass through the output layer (no activation function here because\n",
        "        # CrossEntropyLoss will apply softmax internally)\n",
        "        x = self.fc3(x)  # No activation at output layer\n",
        "        return x\n",
        "\n",
        "# Define transformations: Convert images to tensors and normalize to [-1, 1] range\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize images: mean 0.5, std 0.5 (scale to [-1, 1])\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Load the dataset into DataLoader for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = SimpleNN()  # Initialize the neural network\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
        "\n",
        "# Training loop\n",
        "epochs = 5  # Number of epochs to train for\n",
        "\n",
        "for epoch in range(epochs):  # Iterate over each epoch\n",
        "    running_loss = 0.0  # Track running loss\n",
        "    for i, (inputs, labels) in enumerate(train_loader):  # Iterate over each batch in the training loader\n",
        "\n",
        "        optimizer.zero_grad()  # Clear the gradients from the previous step\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass: Compute model output for the input data\n",
        "\n",
        "        loss = criterion(outputs, labels)  # Compute the loss based on the model's predictions and actual labels\n",
        "\n",
        "        loss.backward()  # Backward pass: Compute gradients for the model parameters\n",
        "\n",
        "        optimizer.step()  # Update the model's parameters using the computed gradients\n",
        "\n",
        "        running_loss += loss.item()  # Accumulate the loss value for monitoring\n",
        "\n",
        "        # Print the average loss every 100 batches\n",
        "        if (i + 1) % 100 == 0:  # Print the running loss every 100 mini-batches\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0  # Reset the running loss after each print\n",
        "\n",
        "print(\"Training Complete.\")  # Training process is finished\n"
      ],
      "metadata": {
        "id": "rlqltPd18O0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333ec3a6-10e7-454b-e072-7b006b724f80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/938], Loss: 1.0164\n",
            "Epoch [1/5], Step [200/938], Loss: 0.4219\n",
            "Epoch [1/5], Step [300/938], Loss: 0.3758\n",
            "Epoch [1/5], Step [400/938], Loss: 0.3530\n",
            "Epoch [1/5], Step [500/938], Loss: 0.3338\n",
            "Epoch [1/5], Step [600/938], Loss: 0.2895\n",
            "Epoch [1/5], Step [700/938], Loss: 0.2672\n",
            "Epoch [1/5], Step [800/938], Loss: 0.2554\n",
            "Epoch [1/5], Step [900/938], Loss: 0.2477\n",
            "Epoch [2/5], Step [100/938], Loss: 0.2198\n",
            "Epoch [2/5], Step [200/938], Loss: 0.2352\n",
            "Epoch [2/5], Step [300/938], Loss: 0.2019\n",
            "Epoch [2/5], Step [400/938], Loss: 0.1816\n",
            "Epoch [2/5], Step [500/938], Loss: 0.2044\n",
            "Epoch [2/5], Step [600/938], Loss: 0.1684\n",
            "Epoch [2/5], Step [700/938], Loss: 0.1843\n",
            "Epoch [2/5], Step [800/938], Loss: 0.1727\n",
            "Epoch [2/5], Step [900/938], Loss: 0.1658\n",
            "Epoch [3/5], Step [100/938], Loss: 0.1577\n",
            "Epoch [3/5], Step [200/938], Loss: 0.1516\n",
            "Epoch [3/5], Step [300/938], Loss: 0.1391\n",
            "Epoch [3/5], Step [400/938], Loss: 0.1354\n",
            "Epoch [3/5], Step [500/938], Loss: 0.1337\n",
            "Epoch [3/5], Step [600/938], Loss: 0.1455\n",
            "Epoch [3/5], Step [700/938], Loss: 0.1443\n",
            "Epoch [3/5], Step [800/938], Loss: 0.1319\n",
            "Epoch [3/5], Step [900/938], Loss: 0.1209\n",
            "Epoch [4/5], Step [100/938], Loss: 0.1114\n",
            "Epoch [4/5], Step [200/938], Loss: 0.1186\n",
            "Epoch [4/5], Step [300/938], Loss: 0.1155\n",
            "Epoch [4/5], Step [400/938], Loss: 0.1156\n",
            "Epoch [4/5], Step [500/938], Loss: 0.1074\n",
            "Epoch [4/5], Step [600/938], Loss: 0.1115\n",
            "Epoch [4/5], Step [700/938], Loss: 0.1165\n",
            "Epoch [4/5], Step [800/938], Loss: 0.1157\n",
            "Epoch [4/5], Step [900/938], Loss: 0.1023\n",
            "Epoch [5/5], Step [100/938], Loss: 0.1055\n",
            "Epoch [5/5], Step [200/938], Loss: 0.0857\n",
            "Epoch [5/5], Step [300/938], Loss: 0.1121\n",
            "Epoch [5/5], Step [400/938], Loss: 0.0944\n",
            "Epoch [5/5], Step [500/938], Loss: 0.0930\n",
            "Epoch [5/5], Step [600/938], Loss: 0.0917\n",
            "Epoch [5/5], Step [700/938], Loss: 0.1001\n",
            "Epoch [5/5], Step [800/938], Loss: 0.0936\n",
            "Epoch [5/5], Step [900/938], Loss: 0.0932\n",
            "Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Explanation of the code:\n",
        "\n",
        "1. **Neural Network Definition**:\n",
        "   - A simple feedforward neural network with two hidden layers (`128` and `64` neurons) and an output layer with `10` neurons (corresponding to the `10` digit classes in MNIST).\n",
        "   - **ReLU** is used as the activation function for the hidden layers, and **CrossEntropyLoss** handles the final output, including applying softmax internally.\n",
        "\n",
        "2. **Data Loading**:\n",
        "   - **MNIST Dataset** is loaded using the `torchvision.datasets.MNIST` class, and images are transformed into tensors and normalized with mean and standard deviation of `0.5`.\n",
        "   - The dataset is split into **training** and **test** sets, and both are loaded using PyTorch’s `DataLoader` to process data in mini-batches.\n",
        "\n",
        "3. **Training Loop**:\n",
        "   - For each **epoch**, the model iterates over mini-batches of size `64` from the training dataset.\n",
        "   - For each mini-batch, the process is:\n",
        "     - **Zero gradients** (resetting gradients from the previous step),\n",
        "     - **Forward pass** to compute predictions,\n",
        "     - **Loss computation** using the `CrossEntropyLoss` function,\n",
        "     - **Backward pass** to calculate gradients,\n",
        "     - **Optimizer step** to update model parameters.\n",
        "   - The loss is printed every `100` mini-batches, and the running loss is reset after each print.\n",
        "\n",
        "4. **Completion**:\n",
        "   - After completing the specified number of epochs, the training process is finished, and the message `\"Training Complete.\"` is printed.\n"
      ],
      "metadata": {
        "id": "EpSpCkJJ8O42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.4. Model Evaluation**\n",
        "- After training the model, it’s essential to evaluate its performance on a separate test dataset.\n",
        "- During evaluation, we use the model to make predictions on unseen data and compare the predictions to the actual labels.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**4.4.1. Evaluating the Model’s Accuracy**\n",
        "\n",
        "After training, we evaluate the model on the test set by calculating its accuracy.\n",
        "\n",
        "**Demonstration: Model Evaluation on Test Set**"
      ],
      "metadata": {
        "id": "uoVblLfT8O8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy of the model on the test set\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set model to evaluation mode to turn off dropout, batch normalization, etc.\n",
        "    correct = 0   # Initialize a counter for correct predictions\n",
        "    total = 0     # Initialize a counter for total samples\n",
        "\n",
        "    # Disable gradient calculation during evaluation, as it reduces memory usage and speeds up computations\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:  # Iterate through each batch in the test loader\n",
        "            # Forward pass: Get model's predictions for the inputs\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Use torch.max to get the class with the highest score (prediction)\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 'predicted' contains the predicted class labels\n",
        "\n",
        "            # Update the total number of samples processed\n",
        "            total += labels.size(0)  # labels.size(0) gives the batch size (number of samples in this batch)\n",
        "\n",
        "            # Count how many predictions were correct by comparing 'predicted' with the actual labels\n",
        "            correct += (predicted == labels).sum().item()  # .sum().item() gives the number of correct predictions in the batch\n",
        "\n",
        "    # Calculate accuracy as the percentage of correctly classified samples\n",
        "    accuracy = 100 * correct / total  # Accuracy = (correct predictions / total samples) * 100\n",
        "\n",
        "    # Print the accuracy result for the test set\n",
        "    print(f'Accuracy of the model on the test set: {accuracy:.2f}%')\n",
        "\n",
        "# Evaluate the model using the test set DataLoader\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "Z40mpYvA8O8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f9808d-c6c2-4b0c-82e2-397939bc1423"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test set: 96.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "- model.eval(): Puts the model in evaluation mode. This disables certain layers like dropout and batch normalization that behave differently during training, ensuring consistent behavior during testing.\n",
        "\n",
        "- torch.no_grad(): Turns off gradient tracking, which saves memory and speeds up the computations since gradients are not needed during evaluation.\n",
        "\n",
        "- torch.max(outputs.data, 1): Gets the predicted class with the highest score (logits) from the model's output. The 1 indicates that the function should find the maximum value along the dimension representing the class scores.\n",
        "\n",
        "- correct += (predicted == labels).sum().item(): Compares the model's predicted labels (predicted) to the actual labels (labels). It counts the number of correct predictions and adds them to the correct variable.\n",
        "\n",
        "- Accuracy Calculation: The accuracy is computed as (correct / total) * 100, representing the percentage of correctly classified samples out of the total number of samples in the test set."
      ],
      "metadata": {
        "id": "_UUUAYUT8O_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.5. Monitoring Training with Metrics**\n",
        "- Monitoring training progress with metrics such as **loss**, **accuracy**, or **precision** and **recall** is important to ensure that the model is learning correctly.\n",
        "- **Training Loss**: If the training loss decreases over time, it generally indicates that the model is learning.\n",
        "- **Validation Loss and Accuracy**: Monitoring these metrics on a validation dataset helps detect **overfitting** (where the model performs well on training data but poorly on unseen data).\n",
        "\n",
        "---\n",
        "\n",
        "**4.5.1. Plotting Loss and Accuracy During Training**\n",
        "\n",
        "Tracking and visualizing the loss and accuracy during training can help understand how well the model is converging.\n",
        "\n",
        "**Demonstration: Plotting Training and Validation Loss**"
      ],
      "metadata": {
        "id": "9XCqUFJv8PBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Variables to store loss values for plotting after training\n",
        "train_loss_history = []  # List to store the average training loss for each epoch\n",
        "val_loss_history = []    # List to store the average validation loss for each epoch\n",
        "\n",
        "for epoch in range(epochs):  # Loop through the specified number of epochs\n",
        "    # Track the running training loss for the current epoch\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train()  # Set the model to training mode (enables dropout, batch normalization, etc.)\n",
        "\n",
        "    for inputs, labels in train_loader:  # Iterate over each mini-batch of data in the training DataLoader\n",
        "        optimizer.zero_grad()  # Clear the gradients from the previous step\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass: Get model predictions for the input batch\n",
        "        loss = criterion(outputs, labels)  # Calculate the loss between predictions and actual labels\n",
        "\n",
        "        loss.backward()  # Backward pass: Compute gradients of the loss with respect to model parameters\n",
        "\n",
        "        optimizer.step()  # Update the model parameters based on the computed gradients\n",
        "\n",
        "        running_loss += loss.item()  # Accumulate the loss for this mini-batch to calculate the average later\n",
        "\n",
        "    # Calculate and store the average training loss for the epoch\n",
        "    avg_train_loss = running_loss / len(train_loader)  # Average loss across all mini-batches in the epoch\n",
        "    train_loss_history.append(avg_train_loss)  # Append the average training loss to the history list\n",
        "\n",
        "    # Calculate validation loss after each epoch\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batch normalization, etc.)\n",
        "    val_loss = 0.0  # Initialize the validation loss for this epoch\n",
        "    with torch.no_grad():  # Disable gradient calculation for the validation loop\n",
        "        for inputs, labels in test_loader:  # Iterate over each mini-batch in the validation DataLoader\n",
        "            outputs = model(inputs)  # Get the model's predictions\n",
        "            loss = criterion(outputs, labels)  # Calculate the loss for the validation data\n",
        "            val_loss += loss.item()  # Accumulate validation loss for each mini-batch\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)  # Calculate the average validation loss for the epoch\n",
        "    val_loss_history.append(avg_val_loss)  # Append the average validation loss to the history list\n",
        "\n",
        "    # Print the average training and validation loss for the current epoch\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.plot(train_loss_history, label='Training Loss')  # Plot training loss history\n",
        "plt.plot(val_loss_history, label='Validation Loss')  # Plot validation loss history\n",
        "plt.xlabel('Epoch')  # Label for x-axis (number of epochs)\n",
        "plt.ylabel('Loss')   # Label for y-axis (loss value)\n",
        "plt.title('Training and Validation Loss over Epochs')  # Plot title\n",
        "plt.legend()  # Display legend to distinguish training and validation loss\n",
        "plt.show()  # Display the plot\n"
      ],
      "metadata": {
        "id": "npyM0Iwd8PBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "d4b9e174-5ce7-482b-fe2a-2802a97d3428"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Training Loss: 0.0877, Validation Loss: 0.1037\n",
            "Epoch [2/5], Training Loss: 0.0784, Validation Loss: 0.1089\n",
            "Epoch [3/5], Training Loss: 0.0696, Validation Loss: 0.0961\n",
            "Epoch [4/5], Training Loss: 0.0642, Validation Loss: 0.0854\n",
            "Epoch [5/5], Training Loss: 0.0588, Validation Loss: 0.0892\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation of the output:**\n",
        "  - **Training Loss**: The training loss consistently decreases over the epochs, indicating that the model is learning and improving its ability to fit the training data. This suggests that the optimization process is working well and the model is converging.\n",
        "\n",
        "  - **Validation Loss**: The validation loss initially decreases but begins to increase slightly towards the end. This could be an early sign of **overfitting**, where the model performs well on the training data but starts to struggle to generalize to unseen data (validation set).\n",
        "\n",
        "  - Insights:\n",
        "    - The model is likely starting to overfit after the second or third epoch, as the gap between training loss and validation loss widens slightly, with validation loss even increasing.\n",
        "    - **Potential actions**:\n",
        "      - **Reduce overfitting**: Techniques like regularization (e.g., weight decay), dropout, or early stopping can help mitigate overfitting.\n",
        "      - **Adjust learning rate**: If the model is converging too fast, lowering the learning rate could help find a better minimum and improve generalization.\n"
      ],
      "metadata": {
        "id": "okod3SOnzdsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Explanation of the code:**\n",
        "\n",
        "1. **`train_loss_history` and `val_loss_history`**: These lists are used to store the average training and validation loss values at each epoch, which will be plotted at the end.\n",
        "  \n",
        "2. **Training Loop**:\n",
        "   - For each **epoch**, the model iterates over the mini-batches in the `train_loader`. After every mini-batch:\n",
        "     - The **forward pass** is performed to calculate predictions.\n",
        "     - The **loss** is computed between the predictions and the true labels.\n",
        "     - The **backward pass** computes the gradients of the loss, which are used to update the model’s parameters via the optimizer.\n",
        "\n",
        "3. **Validation Loss**:\n",
        "   - After training for an epoch, the model is switched to **evaluation mode** (`model.eval()`), which disables certain layers like dropout and batch normalization.\n",
        "   - **Gradient calculation is disabled** during evaluation with `torch.no_grad()` to save memory and computation.\n",
        "   - The validation loss is computed for the entire validation dataset, and the average is stored in `val_loss_history`.\n",
        "\n",
        "4. **Plotting**:\n",
        "   - After training, the losses for each epoch are plotted to visualize the **training and validation loss curves**. This helps monitor the model’s performance over time and detect issues like overfitting.\n",
        "\n",
        "By tracking both training and validation loss, you can observe how well the model is learning and generalizing."
      ],
      "metadata": {
        "id": "PnxWm2n_8PF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **4.6. State-of-the-Art Observations on Training Neural Networks**\n",
        "- **Gradient-Based Optimizers**: Adam, RMSprop, and their variants have become the optimizers of choice in many state-of-the-art deep learning architectures due to their faster convergence and adaptive learning rates. Recent research, such as the **Rectified Adam (RAdam)**, has shown improvements in training stability.\n",
        "  \n",
        "- **Training Stability**: Researchers have observed that training deep neural networks can suffer from **exploding/vanishing gradients**, especially in very deep networks. Techniques like **gradient clipping**, **batch normalization**, and **skip connections** (used in ResNet) help mitigate these problems.\n",
        "\n",
        "- **Learning Rate Scheduling**: Dynamic learning rates using techniques like **learning rate annealing** or **cosine annealing** have improved model convergence in many tasks. Learning rate schedulers adjust the learning rate during training based on the performance, leading to better results.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ichC1eAi8PJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Continuity to the Next Section\n",
        "- In the next section, we will explore **Convolutional Neural Networks (CNNs)**, which are particularly effective for image processing tasks.\n",
        "- We will build CNNs for tasks like image classification and see how they improve performance compared to fully connected networks.\n",
        "\n",
        "This section covered training neural networks in PyTorch, including setting up the training loop, calculating loss, backpropagation, and evaluating model performance. With these basics in place, we are now ready to explore more advanced architectures like Convolutional Neural Networks in the next section."
      ],
      "metadata": {
        "id": "c6SBy-6b8PNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations"
      ],
      "metadata": {
        "id": "zxVetLxDxDMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Does backpropagation exist in a simple feedforward neural network?**\n",
        "\n",
        "Yes, backpropagation exists in a simple feedforward neural network (FFNN). It is the primary method used to train feedforward neural networks by adjusting weights and biases to minimize the loss function.\n",
        "\n",
        "#### Steps in a Feedforward Neural Network:\n",
        "1. **Forward Pass**:\n",
        "   - Input data is passed through the network layer by layer to compute the output (prediction).\n",
        "   \n",
        "2. **Loss Calculation**:\n",
        "   - The difference between the network’s predicted output and the true output is calculated using a loss function (e.g., **CrossEntropyLoss**).\n",
        "\n",
        "3. **Backward Pass (Backpropagation)**:\n",
        "   - Backpropagation computes the gradients of the loss function with respect to each weight and bias by applying the chain rule. This process starts from the output layer and propagates back to the input layer.\n",
        "\n",
        "4. **Weight Update**:\n",
        "   - The optimizer uses the computed gradients to adjust the model's weights and biases to minimize the loss.\n",
        "\n",
        "Backpropagation is integral to training a simple feedforward neural network, as it enables the model to learn by updating its weights during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "SvvhO3q3xE5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "WS0RmYzn0WDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Is backpropagation mandatory in an MLP (Multilayer Perceptron)?**\n",
        "\n",
        "Yes, **backpropagation is mandatory** in an MLP (Multilayer Perceptron) for efficient training and learning.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0qot1U2Xz4Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Why is backpropagation necessary in an MLP?\n",
        "\n",
        "1. **Learning Weights**:\n",
        "   - The main objective of training an MLP is to learn optimal weights and biases that minimize the error between predictions and true labels. Backpropagation provides the gradients needed to adjust these weights.\n",
        "\n",
        "2. **Gradient Descent Optimization**:\n",
        "   - Backpropagation computes the gradients of the loss function with respect to the model’s weights, enabling **gradient descent** or its variants (e.g., **Adam**) to update the parameters.\n",
        "\n",
        "3. **Chain Rule for Gradient Calculation**:\n",
        "   - In an MLP, multiple layers exist between input and output. Backpropagation uses the chain rule to calculate how the error from the output layer influences earlier layers.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4_SfsYfPz-w3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Can an MLP Learn Without Backpropagation?\n",
        "\n",
        "- No, without backpropagation, an MLP would not know how to adjust its weights based on the loss, making it impossible to learn.\n",
        "\n",
        "- Alternative methods (e.g., genetic algorithms) exist but are computationally inefficient for training MLPs compared to backpropagation.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sPAhfUO6z-aL"
      }
    }
  ]
}